openapi: 3.1.1
info:
  title: OpenAI Relay API (BIFL Grade, Remote + Local Fallback)
  version: "1.0.4"

servers:
  - url: https://chatgpt-team-relay.onrender.com/v1

tags:
  - name: Chat
  - name: Completions
  - name: Embeddings
  - name: Images
  - name: Audio
  - name: Assistants
  - name: Threads

paths:
  /chat/completions:
    post:
      operationId: createChatCompletion
      summary: Chat completions (GPT-4, GPT-4o, GPT-3.5, GPT-5)
      tags: [Chat]
      description: |
        Create chat completion (supports streaming).
        This endpoint is routed to the remote OpenAI relay.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionRequest'
      responses:
        '200':
          description: Chat completion result
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionResponse'

  /completions:
    post:
      operationId: createCompletion
      summary: Text completions (legacy/instruct)
      tags: [Completions]
      description: |
        Legacy and instruct text completions, routed to the OpenAI relay.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CompletionRequest'
      responses:
        '200':
          description: Completion result
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CompletionResponse'

  /embeddings:
    post:
      operationId: createEmbedding
      summary: Create embeddings
      tags: [Embeddings]
      description: |
        Creates vector embeddings using the OpenAI relay.  
        For semantic search, you will need to store and compare vectors (in memory or with an external vector store, not via this API).
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/EmbeddingRequest'
      responses:
        '200':
          description: Embedding result
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EmbeddingResponse'

  /images/generations:
    post:
      operationId: createImageGeneration
      summary: Generate image (DALL·E)
      tags: [Images]
      description: |
        Generates images using DALL·E or compatible models through the relay.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ImageGenerationRequest'
      responses:
        '200':
          description: Image generation result
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImageGenerationResponse'

  /audio/transcriptions:
    post:
      operationId: createAudioTranscription
      summary: Audio transcription (Whisper, GPT-4o, local fallback)
      tags: [Audio]
      description: |
        Transcribes speech from audio files using relay models (e.g., whisper-1, gpt-4o-transcribe).
        If relay call fails, local Whisper transcription may be used as fallback.
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/AudioTranscriptionRequest'
      responses:
        '200':
          description: Transcription result
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AudioTranscriptionResponse'

  /audio/speech:
    post:
      operationId: createSpeech
      summary: Text-to-speech (tts-1, gpt-4o, local fallback)
      tags: [Audio]
      description: |
        Converts text to speech using relay models (e.g., tts-1, gpt-4o-mini-tts).
        If relay call fails, local TTS (wav/mp3) fallback may be used.
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/TTSRequest'
      responses:
        '200':
          description: TTS result (audio)
          content:
            audio/mpeg:
              schema:
                type: string
                format: binary

  /models:
    get:
      operationId: listModels
      summary: List available models
      tags: [Chat]
      description: |
        Lists all available models from the relay (may include GPT, DALL·E, Whisper, TTS, etc).
      responses:
        '200':
          description: List of models
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelList'

  /assistants:
    get:
      operationId: listAssistants
      summary: List all assistants (Beta v2)
      tags: [Assistants]
      parameters:
        - name: OpenAI-Beta
          in: header
          required: true
          schema:
            type: string
            enum: ["assistants=v2"]
      responses:
        '200':
          description: List of assistants
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AssistantList'
    post:
      operationId: createAssistant
      summary: Create assistant (Beta v2)
      tags: [Assistants]
      parameters:
        - name: OpenAI-Beta
          in: header
          required: true
          schema:
            type: string
            enum: ["assistants=v2"]
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/AssistantCreateRequest'
      responses:
        '200':
          description: Assistant created
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Assistant'

  /threads:
    post:
      operationId: createThread
      summary: Create thread
      tags: [Threads]
      parameters:
        - name: OpenAI-Beta
          in: header
          required: true
          schema:
            type: string
            enum: ["assistants=v2"]
      requestBody:
        required: false
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ThreadCreateRequest'
      responses:
        '200':
          description: Thread created
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Thread'

  /threads/{thread_id}:
    get:
      operationId: getThread
      summary: Retrieve thread
      tags: [Threads]
      parameters:
        - name: OpenAI-Beta
          in: header
          required: true
          schema:
            type: string
            enum: ["assistants=v2"]
        - name: thread_id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Thread object
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Thread'

components:
  securitySchemes:
    ApiKeyAuth:
      type: http
      scheme: bearer

  schemas:
    # (copy schemas as in earlier YAMLs; unchanged)
    ChatCompletionRequest:
      type: object
      required: [model, messages]
      properties:
        model:
          type: string
        messages:
          type: array
          items:
            type: object
            properties:
              role:
                type: string
              content:
                type: string
    ChatCompletionResponse:
      type: object
      properties:
        id:
          type: string
        object:
          type: string
        choices:
          type: array
          items:
            type: object
            properties:
              message:
                type: object
                properties:
                  role:
                    type: string
                  content:
                    type: string
              finish_reason:
                type: string

    CompletionRequest:
      type: object
      required: [model, prompt]
      properties:
        model:
          type: string
        prompt:
          type: string
    CompletionResponse:
      type: object
      properties:
        id:
          type: string
        object:
          type: string
        choices:
          type: array
          items:
            type: object
            properties:
              text:
                type: string
              finish_reason:
                type: string

    EmbeddingRequest:
      type: object
      required: [model, input]
      properties:
        model:
          type: string
        input:
          type: string
    EmbeddingResponse:
      type: object
      properties:
        object:
          type: string
        data:
          type: array
          items:
            type: object
            properties:
              embedding:
                type: array
                items:
                  type: number

    ImageGenerationRequest:
      type: object
      required: [model, prompt]
      properties:
        model:
          type: string
        prompt:
          type: string
    ImageGenerationResponse:
      type: object
      properties:
        created:
          type: integer
        data:
          type: array
          items:
            type: object
            properties:
              url:
                type: string

    AudioTranscriptionRequest:
      type: object
      required: [file, model]
      properties:
        file:
          type: string
          format: binary
          description: The audio file to transcribe
        model:
          type: string
          description: Model name (e.g. whisper-1)
    AudioTranscriptionResponse:
      type: object
      properties:
        text:
          type: string
          description: The transcript result
        usage:
          type: object
          properties:
            type:
              type: string
              example: duration
            seconds:
              type: number
              example: 3

    TTSRequest:
      type: object
      required: [model, input, voice]
      properties:
        model:
          type: string
        input:
          type: string
        voice:
          type: string

    ModelList:
      type: object
      properties:
        object:
          type: string
        data:
          type: array
          items:
            type: object
            properties:
              id:
                type: string

    AssistantList:
      type: object
      properties:
        data:
          type: array
          items:
            type: object
            properties:
              id:
                type: string

    AssistantCreateRequest:
      type: object
      properties:
        name:
          type: string
        model:
          type: string

    Assistant:
      type: object
      properties:
        id:
          type: string
        object:
          type: string

    ThreadCreateRequest:
      type: object
      properties:
        metadata:
          type: object

    Thread:
      type: object
      properties:
        id:
          type: string
        object:
          type: string

security:
  - ApiKeyAuth: []
